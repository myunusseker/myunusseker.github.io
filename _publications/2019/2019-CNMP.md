---
title:          "Conditional Neural Movement Primitives"
date:           2019-10-14 00:01:00 +0800
selected:       true
#pub:            "IROS"
# pub_pre:        "Submitted to "
# pub_post:       'Under review,'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">RSS 2019 - Accepted</span> '
#pub_date:       "2024"

abstract: >-
   Conditional Neural Movement Primitives (CNMPs)
    is a learning from demonstration framework that is designed as
    a robotic movement learning and generation system built on top
    of a recent deep neural architecture, namely Conditional Neural
    Processes (CNPs). Based on CNPs, CNMPs extract the prior
    knowledge directly from the training data by sampling observations from it, and uses it to predict a conditional distribution
    over any other target points. CNMPs specifically learns complex
    temporal multi-modal sensorimotor relations in connection with
    external parameters and goals; produces movement trajectories
    in joint or task space; and executes these trajectories through a
    high-level feedback control loop. Conditioned with an external
    goal that is encoded in the sensorimotor space of the robot,
    predicted sensorimotor trajectory that is expected to be observed
    during the successful execution of the task is generated by the
    CNMP, and the corresponding motor commands are executed.
    In order to detect and react to unexpected events during
    action execution, CNMP is further conditioned with the actual
    sensor readings in each time-step. Through simulations and real
    robot experiments, we showed that CNMPs can learn the nonlinear relations between low-dimensional parameter spaces and
    complex movement trajectories from few demonstrations; and
    they can also model the associations between high-dimensional
    sensorimotor spaces and complex motions using large number of
    demonstrations. The experiments further showed that even the
    task parameters were not explicitly provided to the system, the
    robot could learn their influence by associating the learned sensorimotor representations with the movement trajectories. The
    robot, for example, learned the influence of object weights and
    shapes through exploiting its sensorimotor space that includes
    proprioception and force measurements; and be able to change
    the movement trajectory on the fly when one  of these factors
    were changed through external intervention.
short_abstract: Conditional Neural Movement Primitives (CNMPs) are a learning-from-demonstration framework that enables robots to generate and adapt complex movement trajectories based on external goals and sensor feedback. Built on Conditional Neural Processes (CNPs), CNMPs learn temporal sensorimotor patterns from demonstrations and produce joint or task-space motions conditioned on goals and real-time sensory input. Experiments show CNMPs can generalize from few or many demonstrations, adapt to factors like object weight or shape, and react to unexpected changes during execution.
cover:          /assets/images/covers/CNMP_cover.png
authors:
  - M. Yunus Seker
  - Mert Imre
  - Justus Piater
  - Emre Ugur
links:
  Paper: https://d1wqtxts1xzle7.cloudfront.net/70064040/Conditional_20Neural_20Movement_20Primitives-libre.pdf?1632240247=&response-content-disposition=inline%3B+filename%3DConditional_Neural_Movement_Primitives.pdf&Expires=1748804166&Signature=Q8rBkrEwR8CglNslGXDTPmuTW6CX9c1mUkU~TkVjroUyQCENfH-ly4SNL50eGPB2ZyfJZis0T4JQY8tgOZ2PHVp4OCZ32ghIS6SRUMaOVOaSiyYAaj3ARALRrLgSBEHw~-ATpK5Ls64r~TgnIlApt-IV3epBgDmxSm3l9wZ2-SIh~i8uahq0dHta-HtPJjaL2~qa-vVtIXjdilbRQ~CcjEwjEfIo9a~Kk0IWNqq1cGJvu1bOzPiDTm0SUCt388VpcME08Wh-uGOWMg710Wb-Tt-C1hLi9jGsQbr3qqrrwPdJKiRf4sK8KauimftBeLf7Ag~dJLFGIAe8vl0raR-D6Q__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA
  Video: https://www.youtube.com/watch?v=Afd5FRrc04I
  Code: https://github.com/myunusseker/CNMP
---
