---
title:          "Grounded Task Axes: Zero-Shot Semantic Skill Generalization via Task-Axis Controllers and Visual Foundation Models"
date:           2025-05-12 00:01:00 +0800
selected:       true
# pub:            "Preprint"
# pub_pre:        "Submitted to "
#pub_post:       'Under review,'
pub_last:       '<span class="badge badge-pill badge-publication badge-info">Humanoids 2025 - Under Review</span>'
#pub_date:       "2025"

abstract: >-
  In this paper, we propose an example-based zero-shot approach to skill transfer. Rather than treating skills as atomic, we decompose skills into a prioritized list of grounded task-axis (GTA) controllers. Each GTAC defines an adaptable controller, such as a position or force controller, along an axis. Importantly, the GTACs are grounded in object key points and axes, e.g., the relative position of a screw head or the axis of its shaft. Zero-shot transfer is thus achieved by finding semantically-similar grounding features on novel target objects. We achieve this example-based grounding of the skills through the use of foundation models, such as SD-DINO, that can detect semantically similar keypoints of objects. We evaluate our framework on real-robot experiments, including screwing, pouring, and spatula scraping tasks, and demonstrate robust and versatile controller transfer for each.
short_abstract: Grounded Task Axes (GTA) introduces a zero-shot skill transfer framework that enables robots to generalize manipulation tasks to unseen objects by grounding modular controllers (like position, force, and orientation) using vision foundation models. It allows robots to perform complex, multi-step tasks—such as scraping, pouring, or inserting—without training or fine-tuning, by matching semantic keypoints between objects.
cover:          /assets/images/covers/GTA_cover.png
authors:
  - M. Yunus Seker
  - Shobhit Aggarwal
  - Oliver Kroemer
links:
  ArXiv: https://arxiv.org/pdf/2505.11680
  Website: https://iamlab-cmu.github.io/GTA/
---
