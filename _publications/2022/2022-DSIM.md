---
title:          "DeepSym: Deep Symbol Generation and Rule Learning for Planning from Unsupervised Robot Interaction"
date:           2022-02-01 00:01:00 +0800
selected:       false
#pub:            "IROS"
# pub_pre:        "Submitted to "
# pub_post:       'Under review,'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">JAIR 2022 - Accepted</span>'
#pub_date:       "2024"

abstract: >-
   Symbolic planning and reasoning are powerful tools for robots tackling complex tasks.
    However, the need to manually design the symbols restrict their applicability, especially for
    robots that are expected to act in open-ended environments. Therefore symbol formation
    and rule extraction should be considered part of robot learning, which, when done properly, will offer scalability, flexibility, and robustness. Towards this goal, we propose a novel
    general method that finds action-grounded, discrete object and effect categories and builds
    probabilistic rules over them for non-trivial action planning. Our robot interacts with objects using an initial action repertoire that is assumed to be acquired earlier and observes
    the effects it can create in the environment. To form action-grounded object, effect, and
    relational categories, we employ a binary bottleneck layer in a predictive, deep encoder-decoder network that takes the image of the scene and the action applied as input, and
    generates the resulting effects in the scene in pixel coordinates. After learning, the binary
    latent vector represents action-driven object categories based on the interaction experience
    of the robot. To distill the knowledge represented by the neural network into rules useful
    for symbolic reasoning, a decision tree is trained to reproduce its decoder function. Probabilistic rules are extracted from the decision paths of the tree and are represented in the
    Probabilistic Planning Domain Definition Language (PPDDL), allowing off-the-shelf planners to operate on the knowledge extracted from the sensorimotor experience of the robot.
    The deployment of the proposed approach for a simulated robotic manipulator enabled the
    discovery of discrete representations of object properties such as ‘rollable’ and ‘insertable’.
    In turn, the use of these representations as symbols allowed the generation of effective
    plans for achieving goals, such as building towers of the desired height, demonstrating the
    effectiveness of the approach for multi-step object manipulation. Finally, we demonstrate
    that the system is not only restricted to the robotics domain by assessing its applicability
    to the MNIST 8-puzzle domain in which learned symbols allow for the generation of plans
    that move the empty tile into any given position.


short_abstract: This paper introduces a novel framework for learning symbolic representations and probabilistic rules directly from a robot’s interaction experience. Using a deep encoder-decoder with a binary bottleneck, the system forms action-grounded object and effect categories from visual observations. It distills these representations into symbolic rules using decision trees, enabling automated planning via Probabilistic PDDL. The approach discovers intuitive concepts like "rollable" and "insertable," and demonstrates effectiveness in multi-step manipulation tasks and symbolic planning domains beyond robotics, such as the MNIST 8-puzzle.
cover:          /assets/images/covers/DSIM_cover.png
authors:
  - Alper Ahmetoglu
  - M. Yunus Seker
  - Justus Piater
  - Erhan Oztop
  - Emre Ugur

links:
  Paper: https://dl.acm.org/doi/pdf/10.1613/jair.1.13754
  Video: https://alpera.xyz/static/deepsym_video.mp4
  Code: https://github.com/alper111/DeepSym
---
